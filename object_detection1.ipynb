{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cdmurray80/object_detection/blob/main/object_detection1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSlhB_p3YM7m"
      },
      "outputs": [],
      "source": [
        "# Docs: https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/2.2.0/install.html#tensorflow-object-detection-api-installation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "wP1CIQ25tO8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TauNjNIrYtdf"
      },
      "outputs": [],
      "source": [
        "# Mount drive\n",
        "#\n",
        "#\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKSCvUtSYz2o"
      },
      "outputs": [],
      "source": [
        "def do_setup():\n",
        "  #\n",
        "  %pip install --ignore-installed --upgrade tensorflow\n",
        "  #\n",
        "  \n",
        "  #\n",
        "  #!pip install tensorflow==2.8\n",
        "  #\n",
        "  #!pip install --ignore-installed --upgrade tensorflow==2.2.0\n",
        "  #!pip uninstall -y tensorflow \n",
        "  #!pip install tensorflow==2.2\n",
        "  !apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n",
        "\n",
        "  import os\n",
        "  if not os.path.isdir('/content/tensorflow'):\n",
        "    %mkdir tensorflow\n",
        "  %cd /content/tensorflow\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models\n",
        "\n",
        "  %cd /content/tensorflow/models/research\n",
        "  %ls\n",
        "  !protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "  %pip install cython\n",
        "  %pip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI\n",
        "\n",
        "  %cd /content/tensorflow/models/research\n",
        "  !cp object_detection/packages/tf2/setup.py .\n",
        "  !python -m pip install --use-feature=2020-resolver .\n",
        "\n",
        "def test_setup():\n",
        "  !python object_detection/builders/model_builder_tf2_test.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDMy05V-ZM2w"
      },
      "outputs": [],
      "source": [
        "do_setup()\n",
        "test_setup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1NaYP3YcPjI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "WORKSPACE_DIR='/content/tensorflow/workspace'\n",
        "test_dir=WORKSPACE_DIR+'/training_demo/images/test'\n",
        "train_dir=WORKSPACE_DIR+'/training_demo/images/train'\n",
        "model_dir=WORKSPACE_DIR+'/training_demo/pre-trained-models'\n",
        "annotations_dir=WORKSPACE_DIR + '/training_demo/annotations'\n",
        "for d in [WORKSPACE_DIR, WORKSPACE_DIR+'/training_demo', WORKSPACE_DIR+'/training_demo/images', annotations_dir, WORKSPACE_DIR+'/training_demo/scripts', train_dir, test_dir, model_dir]:\n",
        "  if not os.path.exists(d):\n",
        "    os.mkdir(d)\n",
        "    print('Created directory', d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gesoZzfdY8f"
      },
      "outputs": [],
      "source": [
        "#Get all xml files\n",
        "import glob,shutil\n",
        "import xml.etree.ElementTree as ET\n",
        "paths=['/content/drive/MyDrive/Research/object_detection/images/final_MLRS', '/content/drive/MyDrive/Research/object_detection/images/final_t72']\n",
        "xml_files=[glob.glob(path+'/*.xml') for path in paths]\n",
        "xml_files=[f for l in xml_files for f in l]\n",
        "\n",
        "#Move to train and test\n",
        "for i,f in enumerate(xml_files):\n",
        "  dir = test_dir if i % 5 == 4 else train_dir\n",
        "  #Get name of actual image file\n",
        "  tree=ET.parse(f)\n",
        "  root=tree.getroot()\n",
        "  img_file=root[1].text\n",
        "  f2=f.replace('.xml', '.'+ img_file.split('.')[-1])\n",
        "  shutil.copy2( f, dir)\n",
        "  shutil.copy2( f2, dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diLiL-e6it-H"
      },
      "outputs": [],
      "source": [
        "#Create label file\n",
        "labels=['MLRS', 'tank']\n",
        "s=''\n",
        "for i,l in enumerate(labels):\n",
        "  s+='''item {\\n \\t id: %d\\n \\t name:'%s'\\n}\\n\\n''' % (i+1, l)\n",
        "#Write file\n",
        "label_file=annotations_dir+'/label_map.pbtxt'\n",
        "text_file = open(label_file, 'w')\n",
        "n = text_file.write(s)\n",
        "text_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTLcg3hDp1t7"
      },
      "outputs": [],
      "source": [
        "# Create train and test tfrecords\n",
        "train_record_file=annotations_dir+'/train.record'\n",
        "test_record_file=annotations_dir+'/test.record'\n",
        "!python /content/drive/MyDrive/Research/object_detection/generate_tfrecord.py -x $train_dir -l $label_file -o $train_record_file\n",
        "!python /content/drive/MyDrive/Research/object_detection/generate_tfrecord.py -x $test_dir -l $label_file -o $test_record_file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erG0SJXdujui"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# More models are here\n",
        "model_name='efficientdet_d1_coco17_tpu-32'\n",
        "model_name='ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "model_name='ssd_resnet50_v1_fpn_640x640_coco17_tpu-8'\n",
        "url = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/'+model_name+'.tar.gz'\n",
        "target_file = WORKSPACE_DIR + '/training_demo/pre-trained-models/'+model_name+'.tar.gz'\n",
        "response = requests.get(url)\n",
        "open(target_file, \"wb\").write(response.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AorOgH3kxgtO"
      },
      "outputs": [],
      "source": [
        "%cd /content/tensorflow/workspace/training_demo/pre-trained-models\n",
        "!tar -xvzf $target_file "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4BpnO-rA1Ih"
      },
      "outputs": [],
      "source": [
        "# Copy raw pipeline config to gdrive\n",
        "gdrive_model_dir='/content/drive/MyDrive/Research/object_detection/'+model_name\n",
        "if not os.path.exists(gdrive_model_dir):\n",
        "    os.mkdir(gdrive_model_dir)\n",
        "shutil.copy2(model_dir+'/' + model_name + '/pipeline.config',gdrive_model_dir+'/raw_pipeline.config')\n",
        "\n",
        "#if I already modified it for a final version, use that\n",
        "final_pipeline_cfg_file=gdrive_model_dir + '/final_pipeline.config'\n",
        "assert(os.path.exists(final_pipeline_cfg_file))\n",
        "shutil.copy2(final_pipeline_cfg_file, model_dir + '/' + model_name + '/pipeline.config')\n",
        "\n",
        "#!ls /content/tensorflow/workspace/training_demo/pre-trained-models/efficientdet_d1_coco17_tpu-32\n",
        "#!cp /content/tensorflow/workspace/training_demo/pre-trained-models/efficientdet_d1_coco17_tpu-32/pipeline.config /content/drive/MyDrive/Research/object_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4dWd-IXHBE6"
      },
      "outputs": [],
      "source": [
        "shutil.copy2('/content/tensorflow/models/research/object_detection/model_main_tf2.py', WORKSPACE_DIR+'/training_demo')\n",
        "shutil.copy2('/content/tensorflow/models/research/object_detection/exporter_main_v2.py', WORKSPACE_DIR+'/training_demo')\n",
        "%cd /content/tensorflow/workspace/training_demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZhhSGztIHnu"
      },
      "outputs": [],
      "source": [
        "%pip install \"opencv-python-headless<4.3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDnIHmGKHZn_"
      },
      "outputs": [],
      "source": [
        "# Actually train!\n",
        "#!python model_main_tf2.py --model_dir=pre-trained-models/$model_name --pipeline_config_path=pre-trained-models/$model_name/pipeline.config\n",
        "!python model_main_tf2.py --model_dir=/content/tensorflow/workspace/training_demo --pipeline_config_path=pre-trained-models/$model_name/pipeline.config\n",
        "#!python model_main_tf2.py --model_dir=. --pipeline_config_path=pre-trained-models/$model_name/pipeline.config"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "#\n",
        "# Use model\n",
        "#\n",
        "#\n",
        "!ls /content/tensorflow/workspace/training_demo"
      ],
      "metadata": {
        "id": "7Z9ZdQI--hX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Export the model\n",
        "#\n",
        "%mkdir -p /content/tensorflow/workspace/training_demo/inference_graph\n",
        "\n",
        "!python exporter_main_v2.py --trained_checkpoint_dir=/content/tensorflow/workspace/training_demo --pipeline_config_path=pre-trained-models/$model_name/pipeline.config --output_directory=/content/tensorflow/workspace/training_demo/inference_graph"
      ],
      "metadata": {
        "id": "vqaWgx4g_zt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import random\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from object_detection.utils import ops\n",
        "from object_detection.utils import visualization_utils as viz\n",
        "from object_detection.utils.label_map_util import create_category_index_from_labelmap\n",
        "\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "szSNHpXC-t0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_image(path):\n",
        "    image_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "    image = Image.open(BytesIO(image_data))\n",
        "    width, height = image.size\n",
        "    shape = (height, width, 3)\n",
        "    image = np.array(image.getdata())\n",
        "    image = image.reshape(shape).astype('uint8')\n",
        "    return image\n",
        "\n",
        "def run_inference(net, image):\n",
        "    image = np.asarray(image)\n",
        "    input_tensor = tf.convert_to_tensor(image)\n",
        "    input_tensor = input_tensor[tf.newaxis, ...]\n",
        "    # forward pass\n",
        "    model = net.signatures['serving_default']\n",
        "    result = model(input_tensor)\n",
        "    # extract detections\n",
        "    num_detections = int(result.pop('num_detections'))\n",
        "    result = {key: value[0, :num_detections].numpy() for key, value in result.items()}\n",
        "    result['num_detections'] = num_detections\n",
        "    result['detection_classes'] = result['detection_classes'].astype('int64')\n",
        "    # use mask if available\n",
        "    if 'detection_masks' in result:\n",
        "        detection_masks_reframed = ops.reframe_box_masks_to_image_masks(result['detection_masks'], result['detection_boxes'], image.shape[0], image.shape[1])\n",
        "        detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5, tf.uint8)\n",
        "        result['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
        "    \n",
        "    return result"
      ],
      "metadata": {
        "id": "X4QQ2iC4_Sop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CATEGORY_IDX = create_category_index_from_labelmap(label_file, use_display_name=True)\n",
        "model_path = '/content/tensorflow/workspace/training_demo/inference_graph/saved_model'\n",
        "model = tf.saved_model.load(model_path)"
      ],
      "metadata": {
        "id": "1bATeHlI_W7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_with_boxes(model, path):\n",
        "    image = load_image(path)\n",
        "    annotation = run_inference(model, image)\n",
        "    masks = annotation.get('detection_masks_reframed', None)\n",
        "    viz.visualize_boxes_and_labels_on_image_array(\n",
        "        image,\n",
        "        annotation['detection_boxes'],\n",
        "        annotation['detection_classes'],\n",
        "        annotation['detection_scores'],\n",
        "        CATEGORY_IDX,\n",
        "        instance_masks=masks,\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=5)\n",
        "    \n",
        "    return image\n",
        "    \n",
        "image_paths = list(glob.glob('/content/drive/MyDrive/Research/object_detection/images/final_t72/*.jpg'))\n",
        "image_paths = random.choices(image_paths, k=6)\n",
        "image_paths"
      ],
      "metadata": {
        "id": "VIXoN_ILBE0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = [get_image_with_boxes(model, path) for path in image_paths]"
      ],
      "metadata": {
        "id": "ueGp1KKFBeHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure, axis = plt.subplots(2, 3, figsize=(15, 10))\n",
        "for index, image in enumerate(images):\n",
        "    row, col = int(index / 3), index % 3\n",
        "    axis[row, col].imshow(image)\n",
        "    axis[row, col].axis('off')"
      ],
      "metadata": {
        "id": "7jkfjL0CBW4d"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "object_detection1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOhlYJiWeWpd6B/33pM2lqu",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}