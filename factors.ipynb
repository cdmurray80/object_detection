{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cdmurray80/object_detection/blob/main/factors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68XHm2Gjx1Wy"
      },
      "outputs": [],
      "source": [
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "np.set_printoptions(precision=4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#\n",
        "# Helper functions\n",
        "#\n",
        "# Given covariance, compute correlation\n",
        "def correlation_from_covariance(covariance):\n",
        "    v = np.sqrt(np.diag(covariance))\n",
        "    outer_v = np.outer(v, v)\n",
        "    correlation = covariance / outer_v\n",
        "    return correlation\n"
      ],
      "metadata": {
        "id": "dbJrzDiqx4UI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# CHANGE THIS AS YOU SEE FIT\n",
        "#\n",
        "# Create our covariance matrix\n",
        "cov_diag_term = 0.5;\n",
        "COV = np.matrix([[1.0,cov_diag_term],[cov_diag_term,1.0]]);\n",
        "\n",
        "\n",
        "#Given covariance and loadings, compute variance.\n",
        "#If loadings represent differences from target, this will return tracking variance\n",
        "def compute_variance(loadings):\n",
        "  return(np.matmul(loadings.transpose(),np.matmul(COV, loadings))[0,0])\n",
        "def compute_variance_xy(x, y):\n",
        "  return compute_variance(np.matrix([[x],[y]]))\n",
        "#\n",
        "# Sanity check, and show \n",
        "assert(cov_diag_term < (COV[0,0]*COV[1,1])**0.5)\n",
        "cor = correlation_from_covariance(COV)\n",
        "print('Covariance:\\n', COV, '\\nCorrelation:\\n', cor)\n"
      ],
      "metadata": {
        "id": "AE2FbbxDtB89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = np.meshgrid(np.linspace(-5, 5, 50),\n",
        "                   np.linspace(-5, 5, 50))\n",
        "fig, ax = plt.subplots(1)\n",
        "v_func = np.vectorize(compute_variance_xy)    # major key!\n",
        "ax.contour(x, y, v_func(x, y), [1., 2., 3., 4., 5.])\n",
        "ax.grid()\n",
        "plt.title( 'Equi-variance contour plot')\n",
        "plt.xlabel('Factor 1 Exposure')\n",
        "plt.ylabel('Factor 2 Exposure')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KJD2ag32ALwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def arrow_w_title(plt_ax, x, y, title, color='b', head_length=0.1, head_width=0.1, x0=0, y0=0):\n",
        "  plt_ax.arrow(x0,y0,x,y, color=color,head_length = head_length, head_width=head_width, length_includes_head=True)\n",
        "  plt_ax.annotate(title, xy=(x,y+0.3))\n",
        "\n",
        "#\n",
        "# Plot vectors to show risk of unit exposure to either factor\n",
        "ax = plt.axes()\n",
        "unit_var = compute_variance(np.matrix([[1.],[1.]]))\n",
        "arrow_w_title(ax, COV[0,0]**0.5,0, 'Factor 1')\n",
        "\n",
        "# This is a bit subtle...we use the covariance to scale our plot so that the\n",
        "# length of a vector with unit exposure to each factor is the risk of \n",
        "# unit exposure that each factor.\n",
        "#factor_2_dx = (unit_var - cov[1,1])**0.5 - cov[0,0]**0.5\n",
        "factor_2_dx = (unit_var - COV[0,0] - COV[1,1])/(2*(COV[0,0]**0.5))\n",
        "factor_2_dy = (COV[1,1] - factor_2_dx**2)**0.5\n",
        "arrow_w_title(ax, factor_2_dx,factor_2_dy, 'Factor 2')\n",
        "arrow_w_title(ax, COV[0,0]**0.5 + factor_2_dx,factor_2_dy, 'Factor1 + Factor2', color='g')\n",
        "ax.set_xlim(-1,6)\n",
        "ax.set_ylim(-1,3)\n",
        "plt.title('Unit exposure to each factor, as well as to both')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WYZGZc7LD9GO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Port 1 has  1 unit  of factor 1 and risk:',compute_variance(np.matrix([[1.],[0.]]))**0.5)\n",
        "print('Port 2 has ~4 units of factor 2 and risk:',compute_variance( np.matrix([[0.],[4.08]]))**0.5)\n",
        "print('Port 3 has  1 unit  of factor 2 and risk:',compute_variance( np.matrix([[0.],[1]]))**0.5)\n",
        "print('Covariance\\n',COV, '\\nCovariance sqroooted\\n', np.sqrt(COV))"
      ],
      "metadata": {
        "id": "LP7aZEGQ0b_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check that the risk of unit exposure to each factor equals the plotted L2 norm\n",
        "print('Risk: {:.5f}, L2 Norm: {:.5f}'.format( unit_var ** 0.5, ((COV[0,0]**0.5 + factor_2_dx)**2 + factor_2_dy**2)** 0.5))"
      ],
      "metadata": {
        "id": "MjxHz4yhuQY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Do eigen decomposition...annoying but we need extra code to sort eigenvectors so it's more than 1 line\n",
        "# Probably 95% of users want the result sorted...idk why it's not an argument to return in sorted order\n",
        "eigenvalues, eigenvectors = np.linalg.eig(COV)\n",
        "idx = (eigenvalues).argsort()[::-1]\n",
        "eigenvectors = eigenvectors[:,idx]\n",
        "eigenvalues = eigenvalues[idx]\n",
        "\n",
        "# Plot samples and eigenvectors\n",
        "samples=np.random.multivariate_normal(np.array([0,0]),COV, size=4000)\n",
        "ax=plt.axes()\n",
        "plt.scatter(samples[:,0],samples[:,1])\n",
        "ax.set_xlim(-6,6)\n",
        "ax.set_ylim(-6,6)\n",
        "for i in range(2):\n",
        "  arrow_w_title(ax, eigenvectors[0,i]*eigenvalues[i]**0.5,eigenvectors[1,i]*eigenvalues[i]**0.5, 'EigVec ' + str(i+1), color='r')\n",
        "  print( 'Eigenvalue ', i, ':\\nValue:', eigenvalues[i], '\\nVector:\\n', eigenvectors[:,i],'\\n\\n')\n",
        "plt.title('Eigenvectors and sample distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "apN3jb_T5wBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now the orthogonal factors are simply the eigenvectors times the raw factors...here I make up 'raw' factor loadings and compute 'orthogonalized' loadings\n",
        "# Annoyingly you have to transpose the eigenvector matrix\n",
        "\n",
        "#\n",
        "# CHANGE NUMBERS HERE IF YOU WANT\n",
        "raw_factor_loadings = np.array([1.,-1.])\n",
        "\n",
        "# Construct 2 x 2 matrics to translate raw factors to orthogonal, and vice versa.\n",
        "# The translation includes both shrinkage and rotation\n",
        "raw_to_orth_matrix = (np.multiply(np.sqrt(eigenvalues),eigenvectors)).transpose()\n",
        "orth_to_raw_matrix = np.linalg.inv(raw_to_orth_matrix)\n",
        "print('Raw to Orthogonal Translation matrix:\\n', raw_to_orth_matrix)\n",
        "print('Orthogonal to Raw Translation matrix:\\n', orth_to_raw_matrix)\n",
        "orth_factor_loadings = np.squeeze(np.asarray(np.matmul(raw_to_orth_matrix, raw_factor_loadings)))\n",
        "recomputed_raw_factor_loadings = np.squeeze(np.asarray(np.matmul(orth_to_raw_matrix, orth_factor_loadings.transpose()).transpose()))\n",
        "print('Raw Factors : ', raw_factor_loadings, '--(orth-space)-->', orth_factor_loadings, '--(raw-space)-->', recomputed_raw_factor_loadings)\n",
        "ax=plt.axes()\n",
        "arrow_w_title(ax, raw_factor_loadings[0], raw_factor_loadings[1], 'Raw Factor')\n",
        "arrow_w_title(ax, orth_factor_loadings[0], orth_factor_loadings[1], 'Orthogonal Factor')\n",
        "ax.set_xlim(-3,3)\n",
        "ax.set_ylim(-2,2)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "jUypGUGJkvwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colors = ['r','g','b', 'y']\n",
        "ax=plt.axes()\n",
        "for i in range(len(colors)):\n",
        "  vec=np.array(np.random.uniform(-1,1, size=[2]))\n",
        "  orth_vec = np.squeeze(np.asarray(np.matmul(raw_to_orth_matrix,vec)))\n",
        "  arrow_w_title(ax, vec[0], vec[1], '', colors[i], head_length=0.0)\n",
        "  arrow_w_title(ax, orth_vec[0], orth_vec[1], '', colors[i], head_length=0.0)\n",
        "  arrow_w_title(ax, orth_vec[0]-vec[0], orth_vec[1]-vec[1], '', colors[i], x0 = vec[0], y0 = vec[1], head_length=0.2, head_width=0.2)\n",
        "\n",
        "ax.set_xlim(-2.5,2.5)\n",
        "ax.set_ylim(-2.5,2.5)\n",
        "plt.title('Vector translations from raw to orthogonal...no arrow means post translation')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2RSuTSZocVNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_variance_orth_factors(orth_loadings):\n",
        "  raw_loadings = np.matmul(orth_to_raw_matrix, orth_loadings.transpose())\n",
        "  return compute_variance(raw_loadings.transpose())\n",
        "def compute_variance_orth_factors_xy(x,y):\n",
        "  return compute_variance_orth_factors(np.array([x,y]))\n",
        "\n",
        "#\n",
        "# Plot iso-risk curves in transformed space\n",
        "x, y = np.meshgrid(np.linspace(-5, 5, 50), np.linspace(-5, 5, 50))\n",
        "fig, ax = plt.subplots(1)\n",
        "v_func_orth = np.vectorize(compute_variance_orth_factors_xy)\n",
        "ax.contour(x, y, v_func_orth(x, y), [1., 2., 3., 4., 5.])\n",
        "ax.grid()\n",
        "plt.title( 'Equi-variance contour plot')\n",
        "plt.xlabel('Orthogonal Factor 1 Exposure')\n",
        "plt.ylabel('Orthogonal Factor 2 Exposure')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fKrQ0XRL95N9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# The following show variance at various points on orth-space.\n",
        "print('The following shows that, in orthogonal space, variaince is coordinate-invariate and orthogonal')\n",
        "for coords in [ [1,0], [0,1],[-1,0],[0,-1], [1,1], [-1,-1], [1,-1], [-1,1]]:\n",
        "  print('Variance at {}: In orth-space {:.6f}, in raw space {:.6f}'.format(coords, compute_variance_orth_factors_xy(coords[0],coords[1]), compute_variance_xy(coords[0],coords[1])))\n",
        "  "
      ],
      "metadata": {
        "id": "xtj7tz7hXVk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UndHB36JfaIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orth_samples = np.matmul(samples, eigenvectors)\n",
        "orth_samples = np.multiply(orth_samples, np.sqrt(eigenvalues))\n",
        "\n",
        "# Use .A1 to get as an array\n",
        "plt.scatter(orth_samples[:,0].A1,orth_samples[:,1].A1)\n",
        "plt.title('Distribution in orthogonal space...note that the axes may be skewed')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sHGDgSgsufdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_variance_xy(-.423, 1.577)"
      ],
      "metadata": {
        "id": "w2K6pHN-8vnN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}